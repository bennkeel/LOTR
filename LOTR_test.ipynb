{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Josh Blaz -- LOTR\n",
    "## CS401 -- NLP\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import urllib.request\n",
    "import lxml.html as lh\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter \n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "#NOTE: Sentiment140 Polarity values: 0: negative, 2: neutral, 4: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Elvish text is translated awkwardly into the .txt format    \n",
    "</br>\n",
    "##### IE:   \n",
    "</br>\n",
    "►M MPR -F+MTRX MP ft PPtK P&RMPht: P. t. The last Two runes are the initials of Thror and Thrain.**  \n",
    "</br>\n",
    "#### Same with some of the intros:\n",
    "</br>\n",
    "“THE LORD OF THE RINGS” \n",
    "\n",
    "Pjrt Thttt \n",
    "\n",
    "THE RETURN \n",
    "OF THE KING \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get all tokens\n",
    "\n",
    "## --- The Silmarillion ---\n",
    "silm_file = open('silmarillion.txt', 'r')\n",
    "silm = silm_file.read() \n",
    "silm_raw = silm[43190:-5436] ## save raw files for later\n",
    "silm = silm.lower() ## Make all words lowercase \n",
    "silm = silm[43190:-5436] ## remove HTML jargon\n",
    "silm = nltk.word_tokenize(silm) ## tokenize\n",
    "\n",
    "## --- The Hobbit ---\n",
    "hobbit_file = open('hobbit.txt', 'r')\n",
    "hobbit = hobbit_file.read()\n",
    "hobbit_raw = hobbit[43212:-8543]\n",
    "hobbit = hobbit.lower()\n",
    "hobbit = hobbit[43212:-8543]\n",
    "hobbit = nltk.word_tokenize(hobbit)\n",
    "\n",
    "## --- The Fellowship of the Ring ---\n",
    "fellowship_file = open('fellowship.txt', 'r')\n",
    "fellowship = fellowship_file.read()\n",
    "fellowship_raw = fellowship[43242:-5436]\n",
    "fellowship = fellowship.lower()\n",
    "fellowship = fellowship[43242:-5436]\n",
    "fellowship = nltk.word_tokenize(fellowship)\n",
    "\n",
    "## --- The Two Towers ---\n",
    "twotowers_file = open('twotowers.txt', 'r')\n",
    "twotowers = twotowers_file.read()\n",
    "twotowers_raw = twotowers[43302:-19245]\n",
    "twotowers = twotowers.lower()\n",
    "twotowers = twotowers[43302:-19245]\n",
    "twotowers = nltk.word_tokenize(twotowers)\n",
    "\n",
    "## --- The Return of the King ---\n",
    "ret_file = open('return.txt', 'r')\n",
    "ret = ret_file.read()\n",
    "ret_raw = ret[43252:-5434]\n",
    "ret = ret.lower()\n",
    "ret = ret[43252:-5434]\n",
    "ret = nltk.word_tokenize(ret)\n",
    "\n",
    "tokenlist = [silm, hobbit, fellowship, twotowers, ret]\n",
    "\n",
    "raw_texts = [silm_raw, hobbit_raw, fellowship_raw, twotowers_raw, ret_raw] #Text files to use with LDA topic modeling\n",
    "\n",
    "\n",
    "entirety = [] ## This is all tokens combined\n",
    "for i in range(len(tokenlist)):\n",
    "    for word in tokenlist[i]:\n",
    "        entirety.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used Chapterize to split books into chapters \n",
    "## https://github.com/JonathanReeve/chapterize\n",
    "### Chapterize didn't work 100% perfectly, so I had to go through and the prologues back in when it cut them out\n",
    "\n",
    "# These are lists containing strings of every chapter for each book\n",
    "silm_chapters = []\n",
    "hobbit_chapters = []\n",
    "fellowship_chapters = []\n",
    "twotowers_chapters = []\n",
    "return_chapters = []\n",
    "\n",
    "# Paths to directories storing book chapters\n",
    "list_of_paths = ['/Users/blaz/Desktop/LOTR/silmarillion-chapters', '/Users/blaz/Desktop/LOTR/hobbit-chapters',\\\n",
    "                '/Users/blaz/Desktop/LOTR/fellowship-chapters', '/Users/blaz/Desktop/LOTR/twotowers-chapters',\\\n",
    "                '/Users/blaz/Desktop/LOTR/return-chapters']\n",
    "\n",
    "for path in list_of_paths: # iterate through the list of folder paths for each book\n",
    "    for file in sorted(glob.glob(os.path.join(path,'*.txt'))): # This gives us a sorted list of the files in each directory                                                         \n",
    "        f = open(file, 'r') # open and read file               # allowing us to read in the chapters in order.\n",
    "        txt = f.read()\n",
    "        ## determine which path we're using and append it to the correct book chapter list\n",
    "        if path == '/Users/blaz/Desktop/LOTR/silmarillion-chapters': \n",
    "            # Because of an issue with 'glob', I had to create a copy of the final chapter in The Silmarillion\n",
    "            silm_chapters.append(txt)\n",
    "        elif path == '/Users/blaz/Desktop/LOTR/hobbit-chapters':\n",
    "            hobbit_chapters.append(txt)\n",
    "        elif path == '/Users/blaz/Desktop/LOTR/fellowship-chapters': \n",
    "            fellowship_chapters.append(txt)\n",
    "        elif path == '/Users/blaz/Desktop/LOTR/twotowers-chapters': \n",
    "            twotowers_chapters.append(txt)\n",
    "        elif path == '/Users/blaz/Desktop/LOTR/return-chapters': \n",
    "            return_chapters.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store chapter names for use in dataframes later\n",
    "\n",
    "silm_chapter_names = [\"Ainundalë\", \"Valaquenta\", \"Of the Beginning of Days\", \"Of Aulë and Yavanna\" , \"Of the Coming of the Elves and the Captivity of Melkor\",\\\n",
    "                     \"Of Thingol and Melian\", \"Of Eldamar and the Princes of the Eldalië\", \"Of Fëanor and the Unchaining of Melkor\", \"Of the Silmarils and the Unrest of the Noldor\",\\\n",
    "                     \"Of the Darkening of Valinor\", \"Of the Flight of the Noldor\", \"Of the Sindar\", \"Of the Sun and Moon and the Hiding of Valinor\", \"Of Men\", \"Of the Return of the Noldor\",\\\n",
    "                     \"Of Beleriad and its Realms\", \"Of the Noldor in Beleriad\", \"Of Maeglin\", \"Of the Coming of Men into the West\", \"Of the Ruin of Beleriad and the Fall of Fingolfin\", \"Of Beren and Lúthien\",\\\n",
    "                     \"Of the Fifth Battle: Nirnaeth Arnoediad\", \"Of Túrin Turambar\", \"Of the Ruin of Doriath\", \"Of Tuor and the Fall of Gondolin\", \"Of the Voyage of Eärendil and the War of Wrath\", \\\n",
    "                     \"Akallabêth: The Downfall of Númenor\", \"Of the Rings of Power and the Third Age\"]\n",
    "\n",
    "hobbit_chapter_names = [\"An Unexpected Party\", \"Roast Mutton\", \"A Short Rest\", \"Over Hill and Under Hill\", \"Riddles In The Dark\", \\\n",
    "                       \"Out Of The Frying-Pan Into The Fire\", \"Queer Lodgings\", \"Flies And Spiders\", \"Barrels Out Of Bond\", \"A Warm Welcome\", \\\n",
    "                       \"On The Doorstep\", \"Inside Information\", \"Not At Home\", \"Fire And Water\", \"The Gathering Of The Clouds\", \"A Thief In The Night\", \\\n",
    "                       \"The Clouds Burst\", \"The Return Journey\", \"The Last Stage\"]\n",
    "\n",
    "fellowship_chapter_names = [\"Concerning Hobbits\", \"Concerning Pipeweed\", \"Of the Ordering of the Shire\", \"Note on the Shire Records\", \"A Long-expected Party\", \"The Shadow of the Past\", \\\n",
    "                           \"Three is Company\", \"A Short Cut to Mushrooms\", \"A Conspiracy Unmasked\", \"The Old Forest\", \"In the House of Tom Bombadil\", \"Fog on the Barrow-downs\", \"At the Sign of the Prancing Pony\",\\\n",
    "                           \"Strider\", \"A Knife in the Dark\", \"Flight to the Ford\", \"Many Meetings\", \"The Council of Elrond\", \"The Ring goes South\", \"A Journey in the Dark\", \"The Bridge of Khazad-dûm\", \\\n",
    "                           \"Lothlórien\", \"The Mirror of Galadriel\", \"Farewell to Lórien\", \"The Great River\", \"The Breaking of the Fellowship\"]\n",
    "\n",
    "twotowers_chapter_names = [\"The Departure of Boromir\", \"The Riders of Rohan\", \"The Uruk-hai\", \"Treebeard\", \"The White Rider\", \"The King of the Golden Hall\", \"Helm's Deep\", \"The Road to Isengard\", \"Flotsam and Jetsam\", \\\n",
    "                          \"The Voice of Saruman\", \"The Palantír\", \"The Taming of Smeagol\", \"The Passage of the Marshes\", \"The Black Gate is Closed\", \"Of Herbs and Stewed Rabbit\", \"The Window of the West\", \"The Forbidden Pool\", \\\n",
    "                          \"Journey to the Cross-roads\", \"The Stairs to Cirith Ungol\", \"Shelob's Lair\", \"The Choices of Master Samwise\"]\n",
    "\n",
    "return_chapter_names = [\"Minas Tirith\", \"The Passing of the Grey Company\", \"The Muster of Rohan\", \"The Siege of Gondor\", \"The Ride of Rohirrim\", \"The Battle of the Pelennor Fields\", \"The Pyre of Denethor\",\\\n",
    "                       \"The Houses of Healing\", \"The Last Debate\", \"The Black Gate Opens\", \"The Tower of Cirith Ungol\", \"The Land of Shadow\", \"Mount Doom\", \"The Field of Cormallen\", \"The Steward and the King\", \\\n",
    "                       \"Many Partings\", \"Homeward Bound\", \"Scouring of the Shire\", \"The Grey Havens\"]\n",
    "\n",
    "chapter_name_list = [silm_chapter_names, hobbit_chapter_names, fellowship_chapter_names, twotowers_chapter_names, return_chapter_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ** 1. Segment all chapters into page-sized objects    **    \n",
    "</br>\n",
    "### ** 2. Send all segments to Sentiment140 API by chapter    **   \n",
    "</br>\n",
    "### ** 3. Calculate polarity averages and polarity lists. **   \n",
    "</br>\n",
    "### ** 4. Store API polarity ratings and export to csv**\n",
    "</br>\n",
    "### ** 5. Plot all polarities + Averages**       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that segments given chapter into n-sized segments to be sent to the API.\n",
    "Typically using n=2940, as this is the #chars in my copy of Fellowship of the Ring.\n",
    "\n",
    "Parameters - chapter - chapter of a book to be broken into segments\n",
    "           - n - length that we segment the text with\n",
    "       \n",
    "Returns a list of (string) segments of the chapter.\n",
    "\"\"\"\n",
    "def Segmenter(chapter, n):\n",
    "    segments = []\n",
    "    # start and end indices for segmenting the text\n",
    "    start = 0\n",
    "    end = n\n",
    "    while end < len(chapter) + n:\n",
    "        segments.append(chapter[start:end])\n",
    "        start = end\n",
    "        end = end + n\n",
    "    return segments #segments of input chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Goal:\n",
    "# Create lists of lists for segments of each chapter of each book, append to them using \"Segmenter\" function, \n",
    "# storing them like this will allow for iterative querying of the API server\n",
    "\n",
    "\n",
    "# Lists of Lists of Lists storing all segments of all chapters for each book\n",
    "# [[chapter1 segment 0-2500, chap1, segmenet 2500-5000]... [chapter2 segment0-2500, ...]...]\n",
    "silm_segments = []\n",
    "hobbit_segments = []\n",
    "fellowship_segments = []\n",
    "twotowers_segments = []\n",
    "return_segments = []\n",
    "\n",
    "# List containing the lists storing each books' chapters\n",
    "list_of_books = [silm_chapters, hobbit_chapters, fellowship_chapters, twotowers_chapters, return_chapters]\n",
    "# List allowing us to access the segment lists\n",
    "list_of_segments = [silm_segments, hobbit_segments, fellowship_segments, twotowers_segments, return_segments]\n",
    "\n",
    "for i in range(len(list_of_books)):\n",
    "    for chapter in list_of_books[i]: # Segment entire chapter using Segmenter function, with 2940 character cuts\n",
    "        list_of_segments[i].append(Segmenter(chapter,2940))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that sends segments of 1 chapter through the Sentiment140 API.\n",
    "In order to do so, it creates and appends segments to a JSON file, then posts the JSON queries to the API server\n",
    "using requests module (using an HTTP Post)\n",
    "\n",
    "Parameters - chapter_segments - segments of an entire chapter of a book\n",
    "\n",
    "Returns a list of polarities for segments of the chapter, as well as the polarity average for the chapter\n",
    "\n",
    "Note: Maximum of 700,000 characters per API request, though this shouldn't be a problem\n",
    "\"\"\"\n",
    "\n",
    "def Polarity(chapter_segments): # segments of a single chapter\n",
    "    request = {'data':[]}\n",
    "    polarityList = []\n",
    "    counter = 0\n",
    "    for segment in chapter_segments: # Fill JSON\n",
    "        request['data'].append({'text':segment})\n",
    "    r = requests.post('http://www.sentiment140.com/api/bulkClassifyJson?appid=blaz_j1@denison.edu', json=request)\n",
    "    jso = r.json()\n",
    "    for i in range(len(request['data'])-1):\n",
    "        polarityList.append(jso['data'][i]['polarity'])\n",
    "    \n",
    "    polarityTotal = 0\n",
    "    for value in polarityList:\n",
    "        polarityTotal = polarityTotal + value\n",
    "    \n",
    "    polarityAVG = polarityTotal/len(polarityList)\n",
    "    return polarityList, polarityAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# store all averages, then store chapter avg, also overall average\n",
    "silm_polarity_avg = []\n",
    "hobbit_polarity_avg = []\n",
    "fellowship_polarity_avg = []\n",
    "twotowers_polarity_avg = []\n",
    "return_polarity_avg = []\n",
    "\n",
    "silm_polarity_lists = []\n",
    "hobbit_polarity_lists = []\n",
    "fellowship_polarity_lists = []\n",
    "twotowers_polarity_lists = []\n",
    "return_polarity_lists = []\n",
    "### Need to get chapter names in\n",
    "\n",
    "for x in range(len(list_of_books)):\n",
    "    book = list_of_books[x]\n",
    "    segs = list_of_segments[x]\n",
    "    \n",
    "    for i in range(len(book)):\n",
    "        if x == 0:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            silm_polarity_lists.append(temp1)\n",
    "            silm_polarity_avg.append(temp2)\n",
    "        if x == 1:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            hobbit_polarity_lists.append(temp1)\n",
    "            hobbit_polarity_avg.append(temp2)\n",
    "        if x == 2:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            fellowship_polarity_lists.append(temp1)\n",
    "            fellowship_polarity_avg.append(temp2)\n",
    "        if x == 3:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            twotowers_polarity_lists.append(temp1)\n",
    "            twotowers_polarity_avg.append(temp2)\n",
    "        if x == 4:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            return_polarity_lists.append(temp1)\n",
    "            return_polarity_avg.append(temp2)\n",
    "\n",
    "all_polarity_avgs = [silm_polarity_avg, hobbit_polarity_avg, fellowship_polarity_avg, twotowers_polarity_avg, return_polarity_avg]\n",
    "\n",
    "all_polarity_lists = [silm_polarity_lists, hobbit_polarity_lists, fellowship_polarity_lists, twotowers_polarity_lists, return_polarity_lists]  \n",
    "# chapter 3 of return of the king is super dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented this all out so I don't reset my excel stuff every time\n",
    "\n",
    "# Converting Polarity AVG data into pandas dataframes\n",
    "## These CSVs store all average chapter polarities for each book\n",
    "silm_df = pd.DataFrame(silm_polarity_avg, index = silm_chapter_names, columns = [\"Polarity\"])\n",
    "silm_df = silm_df.rename_axis(\"--- The Silmarillion ---\")\n",
    "#silm_df.to_csv(\"silm_df.csv\")\n",
    "\n",
    "hobbit_df = pd.DataFrame(hobbit_polarity_avg, index = hobbit_chapter_names, columns = [\"Polarity\"])\n",
    "hobbit_df = hobbit_df.rename_axis(\"--- The Hobbit ---\")\n",
    "#hobbit_df.to_csv(\"hobbit_df.csv\")\n",
    "\n",
    "fellowship_df = pd.DataFrame(fellowship_polarity_avg, index = fellowship_chapter_names, columns = [\"Polarity\"])\n",
    "fellowship_df = fellowship_df.rename_axis(\"--- The Fellowship of the Ring ---\")\n",
    "# Prologue chapters have weird polarities - have solid values because they're shorter\n",
    "#fellowship_df.to_csv(\"fellowship_df.csv\")\n",
    "\n",
    "twotowers_df = pd.DataFrame(twotowers_polarity_avg, index = twotowers_chapter_names, columns = [\"Polarity\"])\n",
    "twotowers_df = twotowers_df.rename_axis(\"--- The Two Towers ---\")\n",
    "#twotowers_df.to_csv(\"twotowers_df.csv\")\n",
    "\n",
    "return_df = pd.DataFrame(return_polarity_avg, index = return_chapter_names, columns = [\"Polarity\"])\n",
    "return_df = return_df.rename_axis(\"--- The Return of the King ---\")\n",
    "#return_df.to_csv(\"return_df.csv\")\n",
    "\n",
    "# Dataframe of all Books overlaid\n",
    "books_df = [silm_df, hobbit_df, fellowship_df, twotowers_df, return_df]\n",
    "full_df = pd.concat(books_df)\n",
    "\n",
    "# Export to CSV\n",
    "full_df.to_csv(\"full_df.csv\")\n",
    "\n",
    "\n",
    "# Exported to Excel as well, for simpler plots\n",
    "excel = pd.ExcelWriter('LOTR1.xlsx')\n",
    "silm_df.to_excel(excel, 'The Silmarillion')\n",
    "hobbit_df.to_excel(excel, 'The Hobbit')\n",
    "fellowship_df.to_excel(excel, 'Fellowship of the Rings')\n",
    "twotowers_df.to_excel(excel, 'The Two Towers')\n",
    "return_df.to_excel(excel, 'The Return of the King')\n",
    "full_df.to_excel(excel, 'Combined')\n",
    "excel.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, commented out data exports\n",
    "\n",
    "# Converting Polarity List data into pandas dataframes\n",
    "## These CSVs store all polarity ratings for each book, rather than average chapter polarity ratings\n",
    "\n",
    "silm_all_pol = []\n",
    "for i in range(len(silm_polarity_lists)):\n",
    "    for polarity in silm_polarity_lists[i]:\n",
    "        if polarity == 0:\n",
    "            polarity = -1\n",
    "        elif polarity == 2:\n",
    "            polarity = 0\n",
    "        else:\n",
    "            polarity = 1\n",
    "        silm_all_pol.append(polarity)\n",
    "silm_all_pol = pd.DataFrame(silm_all_pol, columns = [\"Polarity\"])\n",
    "\n",
    "hobbit_all_pol = []\n",
    "for i in range(len(hobbit_polarity_lists)):\n",
    "    for polarity in hobbit_polarity_lists[i]:\n",
    "        if polarity == 0:\n",
    "            polarity = -1\n",
    "        elif polarity == 2:\n",
    "            polarity = 0\n",
    "        else:\n",
    "            polarity = 1\n",
    "        hobbit_all_pol.append(polarity)\n",
    "hobbit_all_pol = pd.DataFrame(hobbit_all_pol, columns = [\"Polarity\"])\n",
    "\n",
    "fellowship_all_pol = []\n",
    "for i in range(len(fellowship_polarity_lists)):\n",
    "    for polarity in fellowship_polarity_lists[i]:\n",
    "        if polarity == 0:\n",
    "            polarity = -1\n",
    "        elif polarity == 2:\n",
    "            polarity = 0\n",
    "        else:\n",
    "            polarity = 1\n",
    "        fellowship_all_pol.append(polarity)\n",
    "fellowship_all_pol = pd.DataFrame(fellowship_all_pol, columns = [\"Polarity\"])\n",
    "\n",
    "twotowers_all_pol = []\n",
    "for i in range(len(twotowers_polarity_lists)):\n",
    "    for polarity in twotowers_polarity_lists[i]:\n",
    "        if polarity == 0:\n",
    "            polarity = -1\n",
    "        elif polarity == 2:\n",
    "            polarity = 0\n",
    "        else:\n",
    "            polarity = 1\n",
    "        twotowers_all_pol.append(polarity)\n",
    "twotowers_all_pol = pd.DataFrame(twotowers_all_pol, columns = [\"Polarity\"])\n",
    "\n",
    "return_all_pol = []\n",
    "for i in range(len(return_polarity_lists)):\n",
    "    for polarity in return_polarity_lists[i]:\n",
    "        if polarity == 0:\n",
    "            polarity = -1\n",
    "        elif polarity == 2:\n",
    "            polarity = 0\n",
    "        else:\n",
    "            polarity = 1\n",
    "        return_all_pol.append(polarity)\n",
    "return_all_pol = pd.DataFrame(return_all_pol, columns = [\"Polarity\"])\n",
    "\n",
    "all_pol_list = [silm_all_pol, hobbit_all_pol, fellowship_all_pol, twotowers_all_pol, return_all_pol]\n",
    "all_pol = pd.concat(all_pol_list)\n",
    "\n",
    "excel2 = pd.ExcelWriter('LOTR2.xlsx')\n",
    "silm_all_pol.to_excel(excel2, 'The Silmarillion')\n",
    "hobbit_all_pol.to_excel(excel2, 'The Hobbit')\n",
    "fellowship_all_pol.to_excel(excel2, 'Fellowship of the Rings')\n",
    "twotowers_all_pol.to_excel(excel2, 'The Two Towers')\n",
    "return_all_pol.to_excel(excel2, 'The Return of the King')\n",
    "all_pol.to_excel(excel2, 'Combined')\n",
    "\n",
    "excel2.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that tokenizes and cleans the words of every chapter in a book.\n",
    "\n",
    "Parameters - book - a book.\n",
    "\n",
    "Returns a List of Lists storing a tokenized list for every chapter in a book.\n",
    "\"\"\"\n",
    "\n",
    "def Tokenize(book):\n",
    "    punctuation = \".,;!?:`'()’■''\" ## including strange symbols\n",
    "    token_list = []\n",
    "    for chapter in book:\n",
    "        temp = []\n",
    "        words = nltk.word_tokenize(chapter)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word not in punctuation and not word.isnumeric(): # remove punctuation\n",
    "                temp.append(word)\n",
    "        token_list.append(temp)\n",
    "        \n",
    "    return token_list\n",
    "\n",
    "\n",
    "#tokens = (Tokenize(silm_chapters))\n",
    "#print(tokens[0]) ## Tokens of first chapter of The Silmarillion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that returns the n most common words for every chapter in a book.\n",
    "This is accomplished by using 'Counter' in the 'Collections' module.\n",
    "\n",
    "Parameters - book - a tokenized list of lists of all chapters of a book\n",
    "          - n - number of most common words in the chapter\n",
    "          \n",
    "Returns a List of Lists of the n most common words of every chapter in the book.\n",
    "\"\"\"\n",
    "\n",
    "def MostCommon(book, n): \n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    names = [\"gandalf\", \"merry\", \"pippin\", \"frodo\", \"sam\", \"aragorn\", \"faramir\", \"denethor\", \"gimli\", \"legolas\"] # list of common character names\n",
    "    \n",
    "    tolkien_stop = [\"men\",\"great\", \"'s\", \"said\", \"went\", \"he\", \"would\", \"many\", \"one\", \"he\", \"came\", \"yet\", \"even\", \"shall\", \\\n",
    "                   \"upon\", \"days\", \"looked\", \"n't\", \"back\", \"could\", \"'ll\", \"'ve\", \"come\", \"still\", \"gate\", \"'i\" ]\n",
    "    \n",
    "    # Have to get rid of a lot of words, I call these \"tolkien stop words\", the silmarillion is full of these,\n",
    "    # in LOTR, 'great' and 'men' appear very often\n",
    "    \n",
    "    common_words = []\n",
    "    for chapter in book:\n",
    "        temp = []\n",
    "        for word in chapter:\n",
    "            if word not in stop_words and word not in names and word not in tolkien_stop:\n",
    "                temp.append(word)\n",
    "                  \n",
    "        common_words.append(Counter(temp).most_common(n))\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find top 5 NON-STOP words per chapter\n",
    "\n",
    "silm_chapters_tokenized = []\n",
    "hobbit_chapters_tokenized = []\n",
    "fellowship_chapters_tokenized = []\n",
    "twotowers_chapters_tokenized = []\n",
    "return_chapters_tokenized = []\n",
    "\n",
    "\n",
    "silm_chapters_common = []\n",
    "hobbit_chapters_common = []\n",
    "fellowship_chapters_common = []\n",
    "twotowers_chapters_common = []\n",
    "return_chapters_common = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(list_of_books)):\n",
    "    if i == 0:\n",
    "        silm_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        silm_chapters_common = MostCommon(silm_chapters_tokenized, 20)\n",
    "    if i == 1:\n",
    "        hobbit_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        hobbit_chapters_common = MostCommon(hobbit_chapters_tokenized, 20)\n",
    "    if i == 2:\n",
    "        fellowship_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        fellowship_chapters_common = MostCommon(fellowship_chapters_tokenized, 20)\n",
    "    if i == 3:\n",
    "        twotowers_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        twotowers_chapters_common = MostCommon(twotowers_chapters_tokenized, 20)\n",
    "    if i == 4:\n",
    "        return_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        return_chapters_common = MostCommon(return_chapters_tokenized, 20)\n",
    "\n",
    "\n",
    "# Try leaving tolkien words in and show most common words across entire series\n",
    "\n",
    "\n",
    "\n",
    "#### Use this to make Tableau word clouds\n",
    "#### Look up Tableau Word clouds\n",
    "##### Create a data frame for each chapter with all of the words in the chapter, with chapter names as column names\n",
    "####### Send to Tableau\n",
    "\n",
    "#### Also do word clouds for chapters with polarity ratings > 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dark', 28), ('go', 26), ('away', 25), ('long', 24), ('get', 24), ('water', 24), ('way', 22), ('last', 22), ('road', 20), ('along', 20), ('like', 19), ('must', 16), ('see', 16), ('mr.', 16), ('light', 16), ('black', 15), ('beyond', 15), ('ores', 14), ('mordor', 14), ('tower', 13)]\n"
     ]
    }
   ],
   "source": [
    "print(return_chapters_common[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Program showing number of occurrences of word per book\n",
    "\n",
    "## function(word):\n",
    "\n",
    "\n",
    "## returns Silm: x, Hobbit: x, Fellowship: x, etc...\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA - Latent Dirichlet Allocation   \n",
    "</br>\n",
    "-- remove words that are %15 of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book  LDA  \n",
    "</br>\n",
    "-- The book uses 'CountVectorizer' to remove words that appear a lot, but this doesn't actually work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out Topic Modeling on Return of the King first (entire text)\n",
    "\n",
    "ret = open('return.txt', 'r')\n",
    "\n",
    "vect = CountVectorizer(max_features=10000, max_df=.05)\n",
    "# Removes words that appear in at least 15% of the document, then chooses the 10,00 most common words\n",
    "return_of_the_king = vect.fit_transform(ret)\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=100, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0)\n",
    "\n",
    "document_topics = lda.fit_transform(return_of_the_king)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (100, 7618)\n",
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "door          how           went          day           looked        \n",
      "tower         wish          face          beyond        under         \n",
      "answer        full          him           coming        head          \n",
      "below         forgotten     sent          farewell      fallen        \n",
      "line          could         each          sea           eye           \n",
      "from          power         into          grew          up            \n",
      "window        wondered      out           kings         then          \n",
      "themselves    stopped       before        honour        sighed        \n",
      "fled          gathering     presently     next          or            \n",
      "used          guessed       them          before        mouth         \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "should        king          heard         thought       time          \n",
      "need          gondor        nothing       given         rose          \n",
      "why           thjoden       sound         guess         mind          \n",
      "lost          morning       horn          steward       again         \n",
      "foot          field         talk          would         never         \n",
      "have          knights       could         this          seven         \n",
      "fight         men           or            front         meet          \n",
      "speed         great         vanished      companions    remained      \n",
      "dare          mark          loud          out           now           \n",
      "if            lord          them          have          does          \n",
      "\n",
      "\n",
      "topic 10      topic 11      topic 12      topic 13      topic 14      \n",
      "--------      --------      --------      --------      --------      \n",
      "right         she           things        sword         gimli         \n",
      "maybe         jowyn         fell          house         legolas       \n",
      "ere           lady          these         doors         hobbit        \n",
      "dropdown      errand        answered      chapter       strange       \n",
      "horsemen      alas          mountains     elf           shadowfax     \n",
      "their         lord          captain       great         bowed         \n",
      "ia            warden        doubt         then          label         \n",
      "form          would         are           their         victory       \n",
      "wise          have          realm         whose         meriadoc      \n",
      "yet           aragorn       were          out           collectionlink\n",
      "\n",
      "\n",
      "topic 15      topic 16      topic 17      topic 18      topic 19      \n",
      "--------      --------      --------      --------      --------      \n",
      "turned        am            look          walls         white         \n",
      "rode          always        called        houses        silver        \n",
      "tree          glad          forward       swiftly       host          \n",
      "elrond        either        times         from          hill          \n",
      "cotton        mithrandir    ruin          healing       mighty        \n",
      "close         see           met           saw           golden        \n",
      "lords         moving        them          beneath       often         \n",
      "him           are           sit           towers        small         \n",
      "bright        him           their         low           by            \n",
      "back          there         village       them          whom          \n",
      "\n",
      "\n",
      "topic 20      topic 21      topic 22      topic 23      topic 24      \n",
      "--------      --------      --------      --------      --------      \n",
      "save          through       your          any           ever          \n",
      "led           passed        ll            come          might         \n",
      "their         already       get           war           being         \n",
      "now           wind          broken        no            their         \n",
      "strong        trees         running       longer        again         \n",
      "them          half          worse         won           before        \n",
      "empty         gloom         if            because       assault       \n",
      "waiting       grass         or            or            mordor        \n",
      "hardly        fall          now           tidings       or            \n",
      "grief         were          servants      have          yet           \n",
      "\n",
      "\n",
      "topic 25      topic 26      topic 27      topic 28      topic 29      \n",
      "--------      --------      --------      --------      --------      \n",
      "very          night         seen          pass          her           \n",
      "comes         yes           have          most          earth         \n",
      "food          doom          would         part          sprang        \n",
      "till          returned      could         told          she           \n",
      "aid           wait          poor          eastward      middle        \n",
      "were          die           madness       thus          burning       \n",
      "didn          sight         begin         bridge        bent          \n",
      "raised        boromir       grown         tale          enter         \n",
      "here          him           some          seem          vale          \n",
      "have          goes          now           leagues       out           \n",
      "\n",
      "\n",
      "topic 30      topic 31      topic 32      topic 33      topic 34      \n",
      "--------      --------      --------      --------      --------      \n",
      "sam           who           say           rohan         until         \n",
      "well          those         days          fair          evening       \n",
      "frodo         son           good          riders        up            \n",
      "wall          aragorn       such          fields        stars         \n",
      "now           bore          ride          their         came          \n",
      "last          are           least         deeds         rock          \n",
      "dear          love          three         came          from          \n",
      "so            one           ago           travellers    sky           \n",
      "back          lord          long          there         smoke         \n",
      "here          were          so            morgul        behind        \n",
      "\n",
      "\n",
      "topic 35      topic 36      topic 37      topic 38      topic 39      \n",
      "--------      --------      --------      --------      --------      \n",
      "city          darkness      ore           just          did           \n",
      "place         want          hold          knew          made          \n",
      "laid          walk          laughed       paths         minas         \n",
      "aside         image         quite         call          shadows       \n",
      "lifted        companies     gandalf       bilbo         tirith        \n",
      "from          url           perhaps       outside       ready         \n",
      "aloud         bree          him           western       roads         \n",
      "built         style         cover         hobbiton      cross         \n",
      "osgiliath     background    noon          reckon        from          \n",
      "came          img           there         still         dread         \n",
      "\n",
      "\n",
      "topic 40      topic 41      topic 42      topic 43      topic 44      \n",
      "--------      --------      --------      --------      --------      \n",
      "new           no            high          we            words         \n",
      "done          more          folk          shall         their         \n",
      "arms          than          burden        must          remember      \n",
      "horses        there         were          have          else          \n",
      "work          thing         shape         now           faces         \n",
      "standing      now           chamber       our           four          \n",
      "men           riding        many          be            terror        \n",
      "places        horse         crown         come          voices        \n",
      "there         yet           or            then          blood         \n",
      "have          could         great         if            women         \n",
      "\n",
      "\n",
      "topic 45      topic 46      topic 47      topic 48      topic 49      \n",
      "--------      --------      --------      --------      --------      \n",
      "news          black         hope          what          us            \n",
      "cloak         stone         held          know          let           \n",
      "clad          forth         alone         going         weary         \n",
      "rather        like          known         don           course        \n",
      "mail          service       still         do            looking       \n",
      "bed           dream         there         re            or            \n",
      "audio         kept          short         find          come          \n",
      "bad           terrible      light         are           luck          \n",
      "names         muttered      lies          asked         are           \n",
      "elven         out           one           where         then          \n",
      "\n",
      "\n",
      "topic 50      topic 51      topic 52      topic 53      topic 54      \n",
      "--------      --------      --------      --------      --------      \n",
      "others        which         be            way           land          \n",
      "gave          take          will          found         enemy         \n",
      "cold          rest          may           run           nay           \n",
      "cast          care          if            their         lands         \n",
      "him           understand    would         purpose       this          \n",
      "about         him           have          shook         come          \n",
      "or            back          this          reach         rate          \n",
      "body          really        come          now           thither       \n",
      "wrought       enemies       so            long          from          \n",
      "by            now           there         there         whatever      \n",
      "\n",
      "\n",
      "topic 55      topic 56      topic 57      topic 58      topic 59      \n",
      "--------      --------      --------      --------      --------      \n",
      "own           speak         go            first         hands         \n",
      "since         word          turn          ring          proud         \n",
      "main          within        him           sat           lying         \n",
      "download      some          country       growing       rain          \n",
      "him           softly        rider         escape        speech        \n",
      "changed       shield        must          blow          slept         \n",
      "rolled        flying        there         march         lot           \n",
      "php           isildur       then          would         army          \n",
      "stream        now           bearing       dyr           later         \n",
      "comfort       heir          lead          barad         though        \n",
      "\n",
      "\n",
      "topic 60      topic 61      topic 62      topic 63      topic 64      \n",
      "--------      --------      --------      --------      --------      \n",
      "hand          archive       too           between       away          \n",
      "took          org           much          ores          far           \n",
      "saruman       https         people        ruffians      company       \n",
      "dreadful      href          also          chief         sun           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same          details       valley        give          guard         \n",
      "room          title         were          lie           plain         \n",
      "pippin        software      beast         stones        rising        \n",
      "ill           div           galadriel     them          into          \n",
      "kill          library       rivendell     fires         died          \n",
      "one           texts         one           still         out           \n",
      "\n",
      "\n",
      "topic 65      topic 66      topic 67      topic 68      topic 69      \n",
      "--------      --------      --------      --------      --------      \n",
      "shadow        jomer         merry         north         grey          \n",
      "lay           heart         seemed        west          hobbits       \n",
      "bring         against       feet          from          across        \n",
      "him           return        him           east          were          \n",
      "song          best          imrahil       south         turning       \n",
      "pity          journey       pale          captains      spring        \n",
      "change        would         wood          citadel       ship          \n",
      "them          home          ridden        haste         swords        \n",
      "star          amroth        came          closed        them          \n",
      "bade          their         there         there         up            \n",
      "\n",
      "\n",
      "topic 70      topic 71      topic 72      topic 73      topic 74      \n",
      "--------      --------      --------      --------      --------      \n",
      "gate          hills         eyes          side          red           \n",
      "there         green         fire          mountain      ground        \n",
      "weapons       butterbur     were          water         were          \n",
      "their         ahead         wide          open          there         \n",
      "sing          fool          round         hearts        broke         \n",
      "quietly       from          despair       joy           gollum        \n",
      "suppose       sort          dark          by            follow        \n",
      "some          ringing       their         from          gear          \n",
      "valour        having        unless        its           passage       \n",
      "meal          publicdate    foes          up            gates         \n",
      "\n",
      "\n",
      "topic 75      topic 76      topic 77      topic 78      topic 79      \n",
      "--------      --------      --------      --------      --------      \n",
      "even          while         frodo         better        faramir       \n",
      "end           little        mr            reached       battle        \n",
      "slowly        together      hour          shagrat       beregond      \n",
      "bear          silent        cried         crying        brought       \n",
      "bag           mean          there         anyway        nor           \n",
      "command       length        halted        mark          make          \n",
      "falling       then          come          sorrow        followed      \n",
      "now           there         miles         burn          says          \n",
      "if            talked        himself       when          neither       \n",
      "up            if            about         gorbag        him           \n",
      "\n",
      "\n",
      "topic 80      topic 81      topic 82      topic 83      topic 84      \n",
      "--------      --------      --------      --------      --------      \n",
      "dead          soon          old           strength      been          \n",
      "near          path          after         keep          has           \n",
      "drew          sudden        man           him           ve            \n",
      "counsel       steps         master        seems         got           \n",
      "now           climbing      once          hurt          have          \n",
      "were          gleam         peregrin      tears         taken         \n",
      "drawing       out           him           order         long          \n",
      "further       there         see           allowed       so            \n",
      "so            were          crept         chance        back          \n",
      "men           if            tales         begun         come          \n",
      "\n",
      "\n",
      "topic 85      topic 86      topic 87      topic 88      topic 89      \n",
      "--------      --------      --------      --------      --------      \n",
      "denethor      moment        upon          only          voice         \n",
      "enough        caught        stood         span          spoke         \n",
      "among         their         wonder        hidden        clear         \n",
      "none          stroke        father        class         sauron        \n",
      "tall          doing         now           true          friends       \n",
      "them          edge          silence       search        life          \n",
      "swift         mile          there         aria          precious      \n",
      "feel          were          beside        sr            up            \n",
      "sign          from          then          iconochive    thee          \n",
      "so            back          great         bottom        opened        \n",
      "\n",
      "\n",
      "topic 90      topic 91      topic 92      topic 93      topic 94      \n",
      "--------      --------      --------      --------      --------      \n",
      "something     over          div           put           li            \n",
      "script        gone          class         few           data          \n",
      "type          world         col           wild          event         \n",
      "rang          river         sm            men           tracking      \n",
      "mounted       walked        xs            there         click         \n",
      "text          them          row           live          org           \n",
      "brink         down          h5            many          archive       \n",
      "js            memory        top           busy          href          \n",
      "id            age           push          dwelt         php           \n",
      "cries         third         pull          its           https         \n",
      "\n",
      "\n",
      "topic 95      topic 96      topic 97      topic 98      topic 99      \n",
      "--------      --------      --------      --------      --------      \n",
      "indeed        my            cry           deep          road          \n",
      "began         me            sleep         hear          towards       \n",
      "filled        do            peace         death         ran           \n",
      "big           can           young         without       along         \n",
      "linx          think         deadly        living        off           \n",
      "great         have          up            breath        down          \n",
      "kind          if            an            or            up            \n",
      "forget        tell          space         could         from          \n",
      "into          leave         came          some          became        \n",
      "entered       this          waking        there         back          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))\n",
    "\n",
    "# For each topic (a row in the components_), sort the features (ascending)\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "# Get the feature names from the vectorizer\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "\n",
    "mglearn.tools.print_topics(topics=range(100), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(ret, num_topics = 10, id2word=dictionary, passes=15)\n",
    "ldamodel.save('model10.gensim')\n",
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function prepares tokens to be sent through the LDA process. In doing so, it needs to make sure the tokens are\n",
    "words, and that they are lemmas. \n",
    "\"\"\"\n",
    "def LDA_prepare(tokens):\n",
    "    ret_list = []\n",
    "    for word in tokens:\n",
    "        if word not in punctuation and not word.isnumeric() and word.isalpha():\n",
    "            ret_list.append(word)\n",
    "            \n",
    "    for word in ret_list:\n",
    "        word = get_lemma(word)\n",
    "    \n",
    "    return ret_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159452\n",
      "[('the', 8036), ('and', 5815), ('of', 3980), ('to', 2781), ('a', 2340), ('in', 2047), ('he', 1961), ('that', 1732), ('was', 1541), ('it', 1441), ('I', 1431), ('his', 1303), ('you', 1271), ('said', 1156), ('they', 1073), ('not', 984), ('for', 920), ('as', 899), ('with', 873), ('is', 851), ('had', 825), ('on', 783), ('at', 761), ('all', 748), ('be', 698), ('him', 680), ('have', 666), ('but', 636), ('were', 626), ('from', 597), ('now', 589), ('there', 580), (\"'s\", 580), ('will', 570), ('And', 557), ('them', 554), ('But', 533), ('their', 484), ('The', 475), ('Sam', 461), ('up', 457), ('came', 456), ('no', 445), ('we', 445), ('out', 419), ('He', 414), ('if', 411), ('or', 405), ('great', 403), ('Frodo', 387), ('me', 375), ('by', 374), ('are', 374), ('my', 367), ('do', 346), ('would', 337), ('come', 336), ('this', 334), ('more', 323), ('could', 321), ('your', 317), ('so', 311), ('Gandalf', 302), ('like', 295), ('into', 292), ('down', 285), ('then', 284), ('Pippin', 281), ('one', 277), ('upon', 276), (\"n't\", 274), ('before', 271), ('long', 270), ('again', 268), (\"'I\", 268), ('when', 264), ('back', 264), ('been', 263), ('last', 259), ('some', 256), ('’', 254), ('what', 253), ('went', 253), ('away', 250), ('still', 245), ('men', 245), ('than', 244), ('go', 243), ('Then', 240), ('It', 230), ('about', 229), ('shall', 225), ('Aragorn', 222), ('Merry', 222), ('yet', 213), ('see', 212), ('its', 206), ('can', 206), ('many', 204), ('has', 198)]\n"
     ]
    }
   ],
   "source": [
    "### testing, delete afterwards\n",
    "\n",
    "ret_file = open('return.txt', 'r')\n",
    "ret = ret_file.read()\n",
    "\n",
    "## Prepare data for LDA\n",
    "\n",
    "# remove HTML jargon\n",
    "ret1 = ret[:-5434]\n",
    "ret = ret1[43252:]\n",
    "\n",
    "# tokenize entire text\n",
    "words = nltk.word_tokenize(ret)\n",
    "\n",
    "realwords = []\n",
    "punctuation = \".,;!?:`'()\"\n",
    "\n",
    "\n",
    "for word in words:\n",
    "    if word not in punctuation:\n",
    "        realwords.append(word)\n",
    "\n",
    "\n",
    "Count = Counter(realwords).most_common(100)\n",
    "\n",
    "print(len(words))\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (10, 1618)\n",
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "was           him           that          it            on            \n",
      "on            with          it            said          as            \n",
      "as            now           sam           with          they          \n",
      "at            frodo         had           last          up            \n",
      "all           at            for           its           in            \n",
      "frodo         it            could         them          was           \n",
      "with          in            on            sam           could         \n",
      "sam           for           in            at            had           \n",
      "for           but           as            my            only          \n",
      "now           be            go            down          or            \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "but           in            sam           it            had           \n",
      "sam           that          that          you           they          \n",
      "was           it            in            was           as            \n",
      "at            would         was           not           frodo         \n",
      "it            from          there         as            but           \n",
      "him           them          it            had           in            \n",
      "there         was           but           sam           that          \n",
      "in            at            had           him           was           \n",
      "came          they          day           that          no            \n",
      "that          had           all           on            mountain      \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Topic modeling on certain chapters of LOTR\n",
    "path= '/Users/blaz/Desktop/LOTR/return-chapters'\n",
    "\n",
    "for file in sorted(glob.glob(os.path.join(path,'*.txt'))):\n",
    "    if file == \"/Users/blaz/Desktop/LOTR/return-chapters/13.txt\":\n",
    "        break\n",
    "        \n",
    "#print(file)\n",
    "\n",
    "MountDoomFile = open(\"/Users/blaz/Desktop/LOTR/return-chapters/13.txt\", 'r')\n",
    "\n",
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "MountDoom = vect.fit_transform(MountDoomFile)\n",
    "# Count Vectorizer removes all of the words that appear in at least 15% of the text\n",
    "### Unfortunately, this method from the book doesn't work, so I'll have to do this\n",
    "\n",
    "### 10 topics (components)\n",
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0)\n",
    "\n",
    "document_topics = lda.fit_transform(MountDoom)\n",
    "\n",
    "\n",
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))\n",
    "lda.components_.shape: (10, 10000)\n",
    "\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names, \n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 100 topics (components)\n",
    "lda100 = LatentDirichletAllocation(n_components=100, learning_method=\"batch\",\n",
    "                                   max_iter=25, random_state=0)\n",
    "\n",
    "document_topics100 = lda100.fit_transform(MountDoom)\n",
    "\n",
    "topics = np.array([7, 16, 24, 25, 28, 36, 37, 45, 51, 53, 54, 63, 89, 97])\n",
    "\n",
    "sorting = np.argsort(lda100.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "mglearn.tools.print_topics(topics=topics, feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Join all raw text files together\n",
    "\n",
    "lotr_join = [' '.join(filter(str.isalpha, raw.lower().split())) for raw in\n",
    "        raw_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 5\n",
      "INFO:lda:vocab_size: 1679\n",
      "INFO:lda:n_words: 145449\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 500\n",
      "INFO:lda:<0> log likelihood: -1514925\n",
      "INFO:lda:<10> log likelihood: -1204468\n",
      "INFO:lda:<20> log likelihood: -1144126\n",
      "INFO:lda:<30> log likelihood: -1114420\n",
      "INFO:lda:<40> log likelihood: -1096248\n",
      "INFO:lda:<50> log likelihood: -1086189\n",
      "INFO:lda:<60> log likelihood: -1075050\n",
      "INFO:lda:<70> log likelihood: -1067732\n",
      "INFO:lda:<80> log likelihood: -1062163\n",
      "INFO:lda:<90> log likelihood: -1057295\n",
      "INFO:lda:<100> log likelihood: -1053526\n",
      "INFO:lda:<110> log likelihood: -1050247\n",
      "INFO:lda:<120> log likelihood: -1048339\n",
      "INFO:lda:<130> log likelihood: -1047081\n",
      "INFO:lda:<140> log likelihood: -1045232\n",
      "INFO:lda:<150> log likelihood: -1044248\n",
      "INFO:lda:<160> log likelihood: -1041938\n",
      "INFO:lda:<170> log likelihood: -1039694\n",
      "INFO:lda:<180> log likelihood: -1038930\n",
      "INFO:lda:<190> log likelihood: -1035721\n",
      "INFO:lda:<200> log likelihood: -1036558\n",
      "INFO:lda:<210> log likelihood: -1035229\n",
      "INFO:lda:<220> log likelihood: -1033385\n",
      "INFO:lda:<230> log likelihood: -1030560\n",
      "INFO:lda:<240> log likelihood: -1031277\n",
      "INFO:lda:<250> log likelihood: -1031359\n",
      "INFO:lda:<260> log likelihood: -1031333\n",
      "INFO:lda:<270> log likelihood: -1031358\n",
      "INFO:lda:<280> log likelihood: -1030426\n",
      "INFO:lda:<290> log likelihood: -1030572\n",
      "INFO:lda:<300> log likelihood: -1030958\n",
      "INFO:lda:<310> log likelihood: -1029282\n",
      "INFO:lda:<320> log likelihood: -1030000\n",
      "INFO:lda:<330> log likelihood: -1028931\n",
      "INFO:lda:<340> log likelihood: -1026800\n",
      "INFO:lda:<350> log likelihood: -1024969\n",
      "INFO:lda:<360> log likelihood: -1025114\n",
      "INFO:lda:<370> log likelihood: -1024886\n",
      "INFO:lda:<380> log likelihood: -1025515\n",
      "INFO:lda:<390> log likelihood: -1024466\n",
      "INFO:lda:<400> log likelihood: -1024588\n",
      "INFO:lda:<410> log likelihood: -1023486\n",
      "INFO:lda:<420> log likelihood: -1022334\n",
      "INFO:lda:<430> log likelihood: -1022772\n",
      "INFO:lda:<440> log likelihood: -1022978\n",
      "INFO:lda:<450> log likelihood: -1023431\n",
      "INFO:lda:<460> log likelihood: -1023485\n",
      "INFO:lda:<470> log likelihood: -1024149\n",
      "INFO:lda:<480> log likelihood: -1023710\n",
      "INFO:lda:<490> log likelihood: -1024031\n",
      "INFO:lda:<499> log likelihood: -1024523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_topics = 20 # number of topics\n",
    "n_iter = 500 # number of iterations\n",
    "\n",
    "# vectorizer: ignore English stopwords & words that occur less than 5 times\n",
    "cvectorizer = CountVectorizer(min_df=5, stop_words='english')\n",
    "cvz = cvectorizer.fit_transform(lotr_join)\n",
    "\n",
    "# train an LDA model\n",
    "lda_model = lda.LDA(n_topics=n_topics, n_iter=n_iter)\n",
    "\n",
    "#lda_model = LatentDirichletAllocation(n_components=n_topics, learning_method=\"batch\",\n",
    "#                                   max_iter=n_iter, random_state=0)\n",
    "\n",
    "X_topics = lda_model.fit_transform(cvz)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.7,\n",
      "             learning_method='batch', learning_offset=10.0,\n",
      "             max_doc_update_iter=100, max_iter=500, mean_change_tol=0.001,\n",
      "             n_components=20, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
      "             random_state=0, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "print(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great' 'came' 'shall' 'long']\n",
      "['said towers ores riders', 'till caught used sitting', 'gates ways given silence', 'company hope comes follow', 'dwarves time came got', 'sword gathered battle guard', 'old asked began water', 'soon went door gone', 'gandalf think round got', 'end chapter river elrond', 'grey seen ran hear', 'days grew house west', 'looked master does high', 'king men lord city', 'little good thought fell', 'ring told heard called', 'stood black eyes away', 'said like far dark', 'elves people son land', 'great came shall long']\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 4 # number of keywords we show\n",
    "\n",
    "topic_summaries = []\n",
    "topic_word = lda_model.topic_word_  # all topic words\n",
    "vocab = cvectorizer.get_feature_names()\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words + 1):-1] # get!\n",
    "    topic_summaries.append(' '.join(topic_words)) # append!\n",
    "\n",
    "print(topic_words)\n",
    "## 5 most common words per topic\n",
    "print((topic_summaries))\n",
    "\n",
    "# n =4 \n",
    "## gandalf said ring felt\n",
    "## dwarves forest mountain treasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Topic modeling for every book, choose common topic words, topic summary words\n",
    "\n",
    "## Run on every chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate all frequencies\n",
    "\n",
    "silm_freq = {}\n",
    "hobbit_freq = {}\n",
    "fellowship_freq = {}\n",
    "twotowers_freq = {}\n",
    "return_freq = {}\n",
    "\n",
    "freq_dicts = [silm_freq, hobbit_freq, fellowship_freq, twotowers_freq, return_freq]\n",
    "\n",
    "for i in range(len(tokenlist)):\n",
    "    for word in tokenlist[i]:\n",
    "        word = word.lower()\n",
    "        if word not in punctuation and not word.isnumeric() and word.isalpha():\n",
    "            if word in freq_dicts[i]:\n",
    "                freq_dicts[i][word] += 1\n",
    "            else:\n",
    "                freq_dicts[i][word] = 1\n",
    "\n",
    "entirety_dict = {}\n",
    "\n",
    "for word in entirety:\n",
    "    word = word.lower()\n",
    "    if word not in punctuation and not word.isnumeric() and word.isalpha():\n",
    "        if word in entirety_dict:\n",
    "            entirety_dict[word] += 1\n",
    "        else:\n",
    "            entirety_dict[word] = 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "The Silmarillion: 130 Out of 130,115 Words\n",
      "------------------------------------------------------\n",
      "The Hobbit: 2 Out of 95,356 Words\n",
      "------------------------------------------------------\n",
      "The Fellowship of the Ring: 54 Out of 187,790 Words\n",
      "------------------------------------------------------\n",
      "The Two Towers: 220 Out of 156,198 Words\n",
      "------------------------------------------------------\n",
      "The Return of the King: 61 Out of 137,115 Words\n",
      "------------------------------------------------------\n",
      "Entire Corpus: 467\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function that returns the frequency of a given word in each book:\n",
    "\n",
    "Parameters - word - input word\n",
    "\n",
    "Returns the frequency of the input word in each book.\n",
    "\"\"\"\n",
    "\n",
    "#NOTE:: For whatever reason, the words \"orc\" and \"orcs\" were converted to \"ore\" and \"ores\"\n",
    "## I suppose this is the drawback of pulling 5 books off the internet\n",
    "\n",
    "\n",
    "def WordSearch(word):\n",
    "    word = word.lower() \n",
    "    for i in range(len(tokenlist)):\n",
    "        if i == 0:\n",
    "            if word in freq_dicts[i]:\n",
    "                print(\"------------------------------------------------------\")\n",
    "                print(\"The Silmarillion:\", freq_dicts[i][word], \"Out of 130,115 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "            else:\n",
    "                print(\"------------------------------------------------------\")\n",
    "                print(\"The Silmarillion: 0 Out of 130,115 Words\")   \n",
    "                print(\"------------------------------------------------------\")\n",
    "        if i == 1:\n",
    "            if word in freq_dicts[i]:\n",
    "                print(\"The Hobbit:\", freq_dicts[i][word], \"Out of 95,356 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "            else:\n",
    "                print(\"The Hobbit: 0 Out of 95,356 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "        if i == 2:\n",
    "            if word in freq_dicts[i]:\n",
    "                print(\"The Fellowship of the Ring:\", freq_dicts[i][word], \"Out of 187,790 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "            else:\n",
    "                print(\"The Fellowship of the Ring: 0 Out of 187,790 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "        if i == 3:\n",
    "            if word in freq_dicts[i]:\n",
    "                print(\"The Two Towers:\", freq_dicts[i][word], \"Out of 156,198 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "            else:\n",
    "                print(\"The Two Towers: 0 Out of 156,198 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "        if i == 4:\n",
    "            if word in freq_dicts[i]:\n",
    "                print(\"The Return of the King:\", freq_dicts[i][word], \"Out of 137,115 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "            else:\n",
    "                print(\"The Return of the King: 0 Out of 137,115 Words\")\n",
    "                print(\"------------------------------------------------------\")\n",
    "    if word in entirety_dict:\n",
    "        print(\"Entire Corpus:\", entirety_dict[word])\n",
    "        print(\"------------------------------------------------------\")\n",
    "                \n",
    "WordSearch(\"ores\")\n",
    "\n",
    "\n",
    "### Add entirety of text?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lists of words to go to word clouds\n",
    "silm_cloud = []\n",
    "hobbit_cloud = []\n",
    "fellowship_cloud = []\n",
    "twotowers_cloud = []\n",
    "return_cloud = []\n",
    "\n",
    "cloudlist = [silm_cloud, hobbit_cloud, fellowship_cloud, twotowers_cloud, return_cloud]\n",
    "\n",
    "for i in range(len(tokenlist)):\n",
    "    for word in tokenlist[i]:\n",
    "        word=word.lower()\n",
    "        if word not in punctuation and word not in stop_words and not word.isnumeric() and word.isalpha():\n",
    "            if freq_dicts[i][word] > 5: ## Only words that occur 5 times or more\n",
    "                cloudlist[i].append(word)\n",
    "\n",
    "## Dataframes to send to Tableau\n",
    "\n",
    "silm_cloud_df = pd.DataFrame(cloudlist[0], columns = [\"The Silmarillion\"])\n",
    "hobbit_cloud_df = pd.DataFrame(cloudlist[1], columns = [\"The Hobbit\"])\n",
    "fellowship_cloud_df = pd.DataFrame(cloudlist[2], columns = [\"The Fellowship of the Ring\"])\n",
    "twotowers_cloud_df = pd.DataFrame(cloudlist[3], columns = [\"The Two Towers\"])\n",
    "return_cloud_df = pd.DataFrame(cloudlist[4], columns = [\"The Return of the King\"])\n",
    "\n",
    "\n",
    "cloud = pd.ExcelWriter('cloud.xlsx')\n",
    "\n",
    "silm_cloud_df.to_excel(cloud, 'The Silmarillion')\n",
    "hobbit_cloud_df.to_excel(cloud, 'The Hobbit')\n",
    "fellowship_cloud_df.to_excel(cloud, 'Fellowship of the Rings')\n",
    "twotowers_cloud_df.to_excel(cloud, 'The Two Towers')\n",
    "return_cloud_df.to_excel(cloud, 'The Return of the King')\n",
    "\n",
    "cloud.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Negative Word Cloud Exports\n",
    "\n",
    "negative_chapters = []\n",
    "negative_tokens = []\n",
    "negative_words = []\n",
    "\"\"\"\n",
    "A Knife in the Dark\n",
    "The Departure of Boromir\n",
    "The Ride of Rohirrim\n",
    "The Battle of the Pelennor Fields\n",
    "The Pyre of Denethor\n",
    "The Black Gate Opens\n",
    "Mount Doom\n",
    "\"\"\"\n",
    "negative_chapters.append(fellowship_chapters[14])\n",
    "negative_chapters.append(twotowers_chapters[0])\n",
    "negative_chapters.append(return_chapters[4])\n",
    "negative_chapters.append(return_chapters[5])\n",
    "negative_chapters.append(return_chapters[6])\n",
    "negative_chapters.append(return_chapters[9])\n",
    "negative_chapters.append(return_chapters[12])\n",
    "\n",
    "tolkien_stop = [\"men\",\"great\", \"'s\", \"said\", \"went\", \"he\", \"would\", \"many\", \"one\", \"he\", \"came\", \"yet\", \"even\", \"shall\", \\\n",
    "                \"upon\", \"days\", \"looked\", \"n't\", \"back\", \"could\", \"'ll\", \"'ve\", \"come\", \"still\", \"gate\", \"'i\" ]\n",
    "names = [\"gandalf\", \"merry\", \"pippin\", \"frodo\", \"sam\", \"aragorn\", \"faramir\", \"denethor\", \"gimli\", \"legolas\"]\n",
    "for chapter in negative_chapters:\n",
    "    negative_tokens.append(nltk.word_tokenize(chapter))\n",
    "  \n",
    "for i in range(len(negative_tokens)):\n",
    "    for word in negative_tokens[i]:\n",
    "        word = word.lower()\n",
    "        if word not in punctuation and word not in stop_words and not word.isnumeric()\\\n",
    "        and word.isalpha() and word not in tolkien_stop and word not in names:\n",
    "            negative_words.append(word)\n",
    "\n",
    "            \n",
    "neg_df = pd.DataFrame(negative_words, columns = [\"Negative Chapter Words\"])                 \n",
    "neg = pd.ExcelWriter('negative.xlsx')\n",
    "neg_df.to_excel(neg, 'Sheet 1')\n",
    "neg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Positive Word Cloud Exports\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Working with 'glob'\n",
    "\n",
    "path= '/Users/blaz/Desktop/LOTR/silmarillion-chapters'\n",
    "silm_chapters = []\n",
    "\n",
    "for file in sorted(glob.glob(os.path.join(path,'*.txt'))):\n",
    "    print(file)\n",
    "    f = open(file, 'r')\n",
    "    txt = f.read()\n",
    "    silm_chapters.append(txt)\n",
    "    \n",
    "print(len(silm_chapters))\n",
    "print(silm_chapters[len(silm_chapters)-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
