{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Josh Blaz -- LOTR\n",
    "## CS401 -- NLP\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import urllib.request\n",
    "import lxml.html as lh\n",
    "import io\n",
    "import requests\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter \n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "#NOTE: Sentiment140 Polarity values: 0: negative, 2: neutral, 4: positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **NOTE: Elvish text is translated awkwardly into the .txt format    \n",
    "</br>\n",
    "##### IE:   \n",
    "</br>\n",
    "#### ►M MPR -F+MTRX MP ft PPtK P&RMPht: P. t. The last Two runes are the initials of Thror and Thrain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used Chapterize to split books into chapters \n",
    "## https://github.com/JonathanReeve/chapterize\n",
    "### Chapterize didn't work 100% perfectly, so I had to go through and the prologues back in when it cut them out\n",
    "\n",
    "# These are lists containing strings of every chapter for each book\n",
    "silm_chapters = []\n",
    "hobbit_chapters = []\n",
    "fellowship_chapters = []\n",
    "twotowers_chapters = []\n",
    "return_chapters = []\n",
    "\n",
    "# Paths to directories storing book chapters\n",
    "list_of_paths = ['/Users/blaz/Desktop/LOTR/silmarillion-chapters', '/Users/blaz/Desktop/LOTR/hobbit-chapters',\\\n",
    "                '/Users/blaz/Desktop/LOTR/fellowship-chapters', '/Users/blaz/Desktop/LOTR/twotowers-chapters',\\\n",
    "                '/Users/blaz/Desktop/LOTR/return-chapters']\n",
    "\n",
    "for path in list_of_paths: # iterate through the list of folder paths for each book\n",
    "    for file in sorted(glob.glob(os.path.join(path,'*.txt'))): # This gives us a sorted list of the files in each directory                                                         \n",
    "        f = open(file, 'r') # open and read file               # allowing us to read in the chapters in order.\n",
    "        txt = f.read()\n",
    "        ## determine which path we're using and append it to the correct book chapter list\n",
    "        if path == '/Users/blaz/Desktop/LOTR/silmarillion-chapters': \n",
    "            # Because of an issue with 'glob', I had to create a copy of the final chapter in The Silmarillion\n",
    "            silm_chapters.append(txt)\n",
    "        elif path == '/Users/blaz/Desktop/LOTR/hobbit-chapters':\n",
    "            hobbit_chapters.append(txt)\n",
    "        elif path == '/Users/blaz/Desktop/LOTR/fellowship-chapters': \n",
    "            fellowship_chapters.append(txt)\n",
    "        elif path == '/Users/blaz/Desktop/LOTR/twotowers-chapters': \n",
    "            twotowers_chapters.append(txt)\n",
    "        elif path == '/Users/blaz/Desktop/LOTR/return-chapters': \n",
    "            return_chapters.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store chapter names for use in dataframes later\n",
    "\n",
    "silm_chapter_names = [\"Ainundalë\", \"Valaquenta\", \"Of the Beginning of Days\", \"Of Aulë and Yavanna\" , \"Of the Coming of the Elves and the Captivity of Melkor\",\\\n",
    "                     \"Of Thingol and Melian\", \"Of Eldamar and the Princes of the Eldalië\", \"Of Fëanor and the Unchaining of Melkor\", \"Of the Silmarils and the Unrest of the Noldor\",\\\n",
    "                     \"Of the Darkening of Valinor\", \"Of the Flight of the Noldor\", \"Of the Sindar\", \"Of the Sun and Moon and the Hiding of Valinor\", \"Of Men\", \"Of the Return of the Noldor\",\\\n",
    "                     \"Of Beleriad and its Realms\", \"Of the Noldor in Beleriad\", \"Of Maeglin\", \"Of the Coming of Men into the West\", \"Of the Ruin of Beleriad and the Fall of Fingolfin\", \"Of Beren and Lúthien\",\\\n",
    "                     \"Of the Fifth Battle: Nirnaeth Arnoediad\", \"Of Túrin Turambar\", \"Of the Ruin of Doriath\", \"Of Tuor and the Fall of Gondolin\", \"Of the Voyage of Eärendil and the War of Wrath\", \\\n",
    "                     \"Akallabêth: The Downfall of Númenor\", \"Of the Rings of Power and the Third Age\"]\n",
    "\n",
    "hobbit_chapter_names = [\"An Unexpected Party\", \"Roast Mutton\", \"A Short Rest\", \"Over Hill and Under Hill\", \"Riddles In The Dark\", \\\n",
    "                       \"Out Of The Frying-Pan Into The Fire\", \"Queer Lodgings\", \"Flies And Spiders\", \"Barrels Out Of Bond\", \"A Warm Welcome\", \\\n",
    "                       \"On The Doorstep\", \"Inside Information\", \"Not At Home\", \"Fire And Water\", \"The Gathering Of The Clouds\", \"A Thief In The Night\", \\\n",
    "                       \"The Clouds Burst\", \"The Return Journey\", \"The Last Stage\"]\n",
    "\n",
    "fellowship_chapter_names = [\"Concerning Hobbits\", \"Concerning Pipeweed\", \"Of the Ordering of the Shire\", \"Note on the Shire Records\", \"A Long-expected Party\", \"The Shadow of the Past\", \\\n",
    "                           \"Three is Company\", \"A Short Cut to Mushrooms\", \"A Conspiracy Unmasked\", \"The Old Forest\", \"In the House of Tom Bombadil\", \"Fog on the Barrow-downs\", \"At the Sign of the Prancing Pony\",\\\n",
    "                           \"Strider\", \"A Knife in the Dark\", \"Flight to the Ford\", \"Many Meetings\", \"The Council of Elrond\", \"The Ring goes South\", \"A Journey in the Dark\", \"The Bridge of Khazad-dûm\", \\\n",
    "                           \"Lothlórien\", \"The Mirror of Galadriel\", \"Farewell to Lórien\", \"The Great River\", \"The Breaking of the Fellowship\"]\n",
    "\n",
    "twotowers_chapter_names = [\"The Departure of Boromir\", \"The Riders of Rohan\", \"The Uruk-hai\", \"Treebeard\", \"The White Rider\", \"The King of the Golden Hall\", \"Helm's Deep\", \"The Road to Isengard\", \"Flotsam and Jetsam\", \\\n",
    "                          \"The Voice of Saruman\", \"The Palantír\", \"The Taming of Smeagol\", \"The Passage of the Marshes\", \"The Black Gate is Closed\", \"Of Herbs and Stewed Rabbit\", \"The Window of the West\", \"The Forbidden Pool\", \\\n",
    "                          \"Journey to the Cross-roads\", \"The Stairs to Cirith Ungol\", \"Shelob's Lair\", \"The Choices of Master Samwise\"]\n",
    "\n",
    "return_chapter_names = [\"Minas Tirith\", \"The Passing of the Grey Company\", \"The Muster of Rohan\", \"The Siege of Gondor\", \"The Ride of Rohirrim\", \"The Battle of the Pelennor Fields\", \"The Pyre of Denethor\",\\\n",
    "                       \"The Houses of Healing\", \"The Last Debate\", \"The Black Gate Opens\", \"The Tower of Cirith Ungol\", \"The Land of Shadow\", \"Mount Doom\", \"The Field of Cormallen\", \"The Steward and the King\", \\\n",
    "                       \"Many Partings\", \"Homeward Bound\", \"Scouring of the Shire\", \"The Grey Havens\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Steps**\n",
    "</br>\n",
    "### ** 1. Segment all chapters into page-sized objects    **    \n",
    "</br>\n",
    "### ** 2. Send all segments to Sentiment140 API by chapter    **   \n",
    "</br>\n",
    "### ** 3. Calculate polarity averages and polarity lists. **   \n",
    "</br>\n",
    "### ** 4. Store API polarity ratings and send export to csv to plot**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that segments given chapter into a page-sized (2940 character) segments to be sent to the API.\n",
    "\n",
    "Parameters - chapter - chapter of a book to be broken into segments\n",
    "           - cut - length that we segment the text with\n",
    "       \n",
    "Returns a list of (string) segments of the chapter.\n",
    "\"\"\"\n",
    "def Segmenter(chapter, cut):\n",
    "    segments = []\n",
    "    # start and end indices for segmenting the text\n",
    "    start = 0\n",
    "    end = cut\n",
    "    while end < len(chapter) + cut:\n",
    "        segments.append(chapter[start:end])\n",
    "        start = end\n",
    "        end = end + cut\n",
    "    return segments #segments of input chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This function allows us to split the chapters of each book into segments to send in our HTTP-Post JSON requests.   \n",
    "</br>\n",
    "I chose 2940 as the length because this is the exact number of characters per page (including spaces) in my copy of Fellowship of the Ring. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lists of Lists of Lists storing all segments of all chapters for each book\n",
    "# [[chapter1 segment 0-2500, chap1, segmenet 2500-5000]... [chapter2 segment0-2500, ...]...]\n",
    "silm_segments = []\n",
    "hobbit_segments = []\n",
    "fellowship_segments = []\n",
    "twotowers_segments = []\n",
    "return_segments = []\n",
    "\n",
    "# List containing the lists storing each books' chapters\n",
    "list_of_books = [silm_chapters, hobbit_chapters, fellowship_chapters, twotowers_chapters, return_chapters]\n",
    "# List allowing us to access the segment lists\n",
    "list_of_segments = [silm_segments, hobbit_segments, fellowship_segments, twotowers_segments, return_segments]\n",
    "\n",
    "for i in range(len(list_of_books)):\n",
    "    for chapter in list_of_books[i]: # Segment entire chapter using Segmenter function, with 2940 character cuts\n",
    "        list_of_segments[i].append(Segmenter(chapter,2940))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the cell above I create lists of lists for segments of each chapter of each corpus or book, and append to them using my \"Segmenter\"\n",
    "function, storing them neatly like this will allow me to iteratively query the API server. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that sends segments of 1 chapter through the Sentiment140 API.\n",
    "In order to do so, it creates and appends segments to a JSON file, then posts the JSON queries to the API server\n",
    "using requests module (using an HTTP Post)\n",
    "\n",
    "Parameters - chapter_segments - segments of an entire chapter of a book\n",
    "\n",
    "Returns a list of polarities for segments of the chapter, as well as the polarity average for the chapter\n",
    "\n",
    "Note: Maximum of 700,000 characters per API request, though this shouldn't be a problem\n",
    "\"\"\"\n",
    "\n",
    "def Polarity(chapter_segments): # segments of a single chapter\n",
    "    request = {'data':[]}\n",
    "    polarityList = []\n",
    "    counter = 0\n",
    "    for segment in chapter_segments: # Fill JSON\n",
    "        request['data'].append({'text':segment})\n",
    "    r = requests.post('http://www.sentiment140.com/api/bulkClassifyJson?appid=blaz_j1@denison.edu', json=request)\n",
    "    jso = r.json()\n",
    "    for i in range(len(request['data'])-1):\n",
    "        polarityList.append(jso['data'][i]['polarity'])\n",
    "    \n",
    "    polarityTotal = 0\n",
    "    for value in polarityList:\n",
    "        polarityTotal = polarityTotal + value\n",
    "    \n",
    "    polarityAVG = polarityTotal/len(polarityList)\n",
    "    #print(polarityList)\n",
    "    return polarityList, polarityAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silm\n",
      "hobbit\n",
      "fellowship\n",
      "two towers\n",
      "return of the king\n"
     ]
    }
   ],
   "source": [
    "# This function takes about a minute to run\n",
    "\n",
    "# store all averages, then store chapter avg, also overall average\n",
    "silm_polarity_avg = []\n",
    "hobbit_polarity_avg = []\n",
    "fellowship_polarity_avg = []\n",
    "twotowers_polarity_avg = []\n",
    "return_polarity_avg = []\n",
    "\n",
    "silm_polarity_lists = []\n",
    "hobbit_polarity_lists = []\n",
    "fellowship_polarity_lists = []\n",
    "twotowers_polarity_lists = []\n",
    "return_polarity_lists = []\n",
    "### Need to get chapter names in\n",
    "\n",
    "for x in range(len(list_of_books)):\n",
    "    book = list_of_books[x]\n",
    "    segs = list_of_segments[x]\n",
    "    \n",
    "    for i in range(len(book)):\n",
    "        if x == 0:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            silm_polarity_lists.append(temp1)\n",
    "            silm_polarity_avg.append(temp2)\n",
    "        if x == 1:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            hobbit_polarity_lists.append(temp1)\n",
    "            hobbit_polarity_avg.append(temp2)\n",
    "        if x == 2:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            fellowship_polarity_lists.append(temp1)\n",
    "            fellowship_polarity_avg.append(temp2)\n",
    "        if x == 3:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            twotowers_polarity_lists.append(temp1)\n",
    "            twotowers_polarity_avg.append(temp2)\n",
    "        if x == 4:\n",
    "            temp1 = []\n",
    "            temp2 = 0.0\n",
    "            temp1,temp2 = Polarity(segs[i])\n",
    "            return_polarity_lists.append(temp1)\n",
    "            return_polarity_avg.append(temp2)\n",
    "\n",
    "all_polarity_avgs = [silm_polarity_avg, hobbit_polarity_avg, fellowship_polarity_avg, twotowers_polarity_avg, return_polarity_avg]\n",
    "\n",
    "all_polarity_lists = [silm_polarity_lists, hobbit_polarity_lists, fellowship_polarity_lists, twotowers_polarity_lists, return_polarity_lists]  \n",
    "# chapter 3 of return of the king is super dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Export to Excel\\npd.read_excel(\\'file.xlsx\\')\\nfull_df.to_csv(\"full_df.csv\")\\npd.to_excel(\\'dir/myDataFrame.xlsx\\', sheet_name=\\'Sheet1\\')\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting AVG data into pandas dataframes\n",
    "\n",
    "silm_df = pd.DataFrame(silm_polarity_avg, index = silm_chapter_names, columns = [\"Polarity\"])\n",
    "silm_df = silm_df.rename_axis(\"--- The Silmarillion ---\")\n",
    "#silm_df.to_csv(\"silm_df.csv\")\n",
    "\n",
    "hobbit_df = pd.DataFrame(hobbit_polarity_avg, index = hobbit_chapter_names, columns = [\"Polarity\"])\n",
    "hobbit_df = hobbit_df.rename_axis(\"--- The Hobbit ---\")\n",
    "#hobbit_df.to_csv(\"hobbit_df.csv\")\n",
    "\n",
    "fellowship_df = pd.DataFrame(fellowship_polarity_avg, index = fellowship_chapter_names, columns = [\"Polarity\"])\n",
    "fellowship_df = fellowship_df.rename_axis(\"--- The Fellowship of the Ring ---\")\n",
    "# Prologue chapters have weird polarities - have solid values because they're shorter\n",
    "#fellowship_df.to_csv(\"fellowship_df.csv\")\n",
    "\n",
    "twotowers_df = pd.DataFrame(twotowers_polarity_avg, index = twotowers_chapter_names, columns = [\"Polarity\"])\n",
    "twotowers_df = twotowers_df.rename_axis(\"--- The Two Towers ---\")\n",
    "#twotowers_df.to_csv(\"twotowers_df.csv\")\n",
    "\n",
    "return_df = pd.DataFrame(return_polarity_avg, index = return_chapter_names, columns = [\"Polarity\"])\n",
    "return_df = return_df.rename_axis(\"--- The Return of the King ---\")\n",
    "#return_df.to_csv(\"return_df.csv\")\n",
    "# Really dark novel\n",
    "\n",
    "# Dataframe of all Books overlaid\n",
    "books_df = [silm_df, hobbit_df, fellowship_df, twotowers_df, return_df]\n",
    "#full_df = pd.concat(books_df)\n",
    "\n",
    "# Export to CSV\n",
    "#full_df.to_csv(\"full_df.csv\")\n",
    "\n",
    "\"\"\"\n",
    "# Export to Excel\n",
    "pd.read_excel('file.xlsx')\n",
    "full_df.to_csv(\"full_df.csv\")\n",
    "pd.to_excel('dir/myDataFrame.xlsx', sheet_name='Sheet1')\n",
    "\"\"\"\n",
    "\n",
    "# Add another column for topic, once topic modeling is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ainundalë                                                 0.0\n",
      "Valaquenta                                                4.0\n",
      "Of the Beginning of Days                                  4.0\n",
      "Of Aulë and Yavanna                                       0.0\n",
      "Of the Coming of the Elves and the Captivity of Melkor    4.0\n",
      "Of Thingol and Melian                                     NaN\n",
      "Of Eldamar and the Princes of the Eldalië                 4.0\n",
      "Of Fëanor and the Unchaining of Melkor                    0.0\n",
      "Of the Silmarils and the Unrest of the Noldor             0.0\n",
      "Of the Darkening of Valinor                               0.0\n",
      "Of the Flight of the Noldor                               0.0\n",
      "Of the Sindar                                             0.0\n",
      "Of the Sun and Moon and the Hiding of Valinor             4.0\n",
      "Of Men                                                    NaN\n",
      "Of the Return of the Noldor                               2.0\n",
      "Of Beleriad and its Realms                                4.0\n",
      "Of the Noldor in Beleriad                                 2.0\n",
      "Of Maeglin                                                0.0\n",
      "Of the Coming of Men into the West                        2.0\n",
      "Of the Ruin of Beleriad and the Fall of Fingolfin         0.0\n",
      "Of Beren and Lúthien                                      4.0\n",
      "Of the Fifth Battle: Nirnaeth Arnoediad                   2.0\n",
      "Of Túrin Turambar                                         0.0\n",
      "Of the Ruin of Doriath                                    0.0\n",
      "Of Tuor and the Fall of Gondolin                          0.0\n",
      "Of the Voyage of Eärendil and the War of Wrath            4.0\n",
      "Akallabêth: The Downfall of Númenor                       0.0\n",
      "Of the Rings of Power and the Third Age                   0.0\n",
      "Name: 2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "silm_pl_df = pd.DataFrame(silm_polarity_lists, index = silm_chapter_names)\n",
    "#print(silm_pl_df)\n",
    "\n",
    "print(silm_pl_df[2])\n",
    "#silm_pl_df.to_csv(\"silm_pl_df_new.csv\")\n",
    "\n",
    "\n",
    "# Need help plotting this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that tokenizes the words of every chapter in a book.\n",
    "\n",
    "Parameters - book - a book.\n",
    "\n",
    "Returns a List of Lists storing a tokenized list for every chapter in a book.\n",
    "\"\"\"\n",
    "\n",
    "def Tokenize(book):\n",
    "    punctuation = \".,;!?:`'()\"\n",
    "    token_list = []\n",
    "    for chapter in book:\n",
    "        temp = []\n",
    "        words = nltk.word_tokenize(chapter)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word not in punctuation and not word.isnumeric(): # remove punctuation\n",
    "                temp.append(word)\n",
    "        token_list.append(temp)\n",
    "        \n",
    "    return token_list\n",
    "\n",
    "\n",
    "#tokens = (Tokenize(silm_chapters))\n",
    "#print(tokens[0]) ## Tokens of first chapter of The Silmarillion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that returns the n most common words for every chapter in a book.\n",
    "This is accomplished by using 'Counter' in the 'Collections' module.\n",
    "\n",
    "Parameter - book - a tokenized list of lists of all chapters of a book\n",
    "          - n - number of most common words in the chapter\n",
    "          \n",
    "Returns a List of Lists of the n most common words of every chapter in the book.\n",
    "\"\"\"\n",
    "\n",
    "def MostCommon(book, n):\n",
    "    from collections import Counter \n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    \n",
    "    names = [\"gandalf\", \"merry\", \"pippin\", \"frodo\", \"sam\", \"aragorn\", \"faramir\", \"denethor\", \"gimli\", \"legolas\"] # list of common character names\n",
    "    \n",
    "    tolkien_stop = [\"men\",\"great\", \"'s\", \"said\", \"went\", \"he\", \"would\", \"many\", \"one\", \"he\", \"came\", \"yet\", \"even\", \"shall\", \\\n",
    "                   \"upon\", \"days\", \"looked\", \"n't\", \"back\", \"could\", \"'ll\", \"'ve\", \"come\", \"still\", \"gate\", \"'i\" ]\n",
    "    # Have to get rid of a lot of words, I call these \"tolkien stop words\", the silmarillion is full of these,\n",
    "    # in LOTR, 'great' and 'men' appear very often\n",
    "    \n",
    "    common_words = []\n",
    "    for chapter in book:\n",
    "        temp = []\n",
    "        for word in chapter:\n",
    "            if word not in stop_words and word not in names and word not in tolkien_stop:\n",
    "                temp.append(word)\n",
    "                  \n",
    "        common_words.append(Counter(temp).most_common(10))\n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find top 5 NON-STOP words per chapter\n",
    "\n",
    "silm_chapters_tokenized = []\n",
    "hobbit_chapters_tokenized = []\n",
    "fellowship_chapters_tokenized = []\n",
    "twotowers_chapters_tokenized = []\n",
    "return_chapters_tokenized = []\n",
    "\n",
    "\n",
    "silm_chapters_common = []\n",
    "hobbit_chapters_common = []\n",
    "fellowship_chapters_common = []\n",
    "twotowers_chapters_common = []\n",
    "return_chapters_common = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(list_of_books)):\n",
    "    if i == 0:\n",
    "        silm_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        silm_chapters_common = MostCommon(silm_chapters_tokenized, 5)\n",
    "    if i == 1:\n",
    "        hobbit_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        hobbit_chapters_common = MostCommon(hobbit_chapters_tokenized, 5)\n",
    "    if i == 2:\n",
    "        fellowship_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        fellowship_chapters_common = MostCommon(fellowship_chapters_tokenized, 5)\n",
    "    if i == 3:\n",
    "        twotowers_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        twotowers_chapters_common = MostCommon(twotowers_chapters_tokenized, 5)\n",
    "    if i == 4:\n",
    "        return_chapters_tokenized = Tokenize(list_of_books[i])\n",
    "        return_chapters_common = MostCommon(return_chapters_tokenized, 5)\n",
    "\n",
    "\n",
    "# Try leaving tolkien words in and show most common words across entire series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA - Latent Dirichlet Allocation   \n",
    "</br>\n",
    "-- remove words that are %15 of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out Topic Modeling on Return of the King first (entire text)\n",
    "\n",
    "ret = open('return.txt', 'r')\n",
    "\n",
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "# Removes words that appear in at least 15% of the document, then chooses the 10,00 most common words\n",
    "return_of_the_king = vect.fit_transform(ret)\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=100, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0)\n",
    "\n",
    "document_topics = lda.fit_transform(return_of_the_king)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (100, 7637)\n",
      "topic 0       topic 1       topic 2       topic 3       topic 4       \n",
      "--------      --------      --------      --------      --------      \n",
      "slowly        look          other         man           what          \n",
      "father        they          world         till          can           \n",
      "breath        place         with          old           see           \n",
      "towers        as            known         crept         is            \n",
      "whom          were          there         purpose       do            \n",
      "label         life          men           raised        them          \n",
      "event         by            some          was           says          \n",
      "collectionlinkall           in            by            in            \n",
      "click         met           it            out           there         \n",
      "detailspage   in            dernhelm      with          escape        \n",
      "\n",
      "\n",
      "topic 5       topic 6       topic 7       topic 8       topic 9       \n",
      "--------      --------      --------      --------      --------      \n",
      "shadow        less          could         shire         food          \n",
      "once          than          seen          riders        that          \n",
      "sat           bring         be            son           audio         \n",
      "at            because       but           in            straight      \n",
      "under         love          nothing       sauron        up            \n",
      "on            worse         see           told          beat          \n",
      "they          roads         as            country       mood          \n",
      "he            greater       use           realm         stared        \n",
      "came          precious      he            deeds         for           \n",
      "bent          meriadoc      no            main          in            \n",
      "\n",
      "\n",
      "topic 10      topic 11      topic 12      topic 13      topic 14      \n",
      "--------      --------      --------      --------      --------      \n",
      "clear         dark          ll            tell          stone         \n",
      "sky           lay           think         name          beregond      \n",
      "stars         in            don           in            minas         \n",
      "wood          deep          get           closed        hands         \n",
      "crown         light         just          woods         tirith        \n",
      "upon          on            they          dream         wall          \n",
      "yourself      part          all           ended         sent          \n",
      "in            open          want          thrust        they          \n",
      "brother       plain         there         doors         peregrin      \n",
      "edge          it            but           front         fight         \n",
      "\n",
      "\n",
      "topic 15      topic 16      topic 17      topic 18      topic 19      \n",
      "--------      --------      --------      --------      --------      \n",
      "never         not           is            thought       high          \n",
      "among         did           said          mind          above         \n",
      "fall          may           gandalf       gave          search        \n",
      "that          do            time          began         in            \n",
      "gloom         but           he            at            it            \n",
      "led           should        this          least         was           \n",
      "them          be            for           he            ten           \n",
      "tears         he            but           yes           there         \n",
      "hall          that          no            it            were          \n",
      "in            it            am            cotton        that          \n",
      "\n",
      "\n",
      "topic 20      topic 21      topic 22      topic 23      topic 24      \n",
      "--------      --------      --------      --------      --------      \n",
      "first         end           li            go            gimli         \n",
      "off           west          php           must          legolas       \n",
      "together      walls         about         take          others        \n",
      "as            coming        target        be            looking       \n",
      "they          evil          data          but           they          \n",
      "move          in            _top          now           said          \n",
      "honour        thing         download      we            that          \n",
      "for           from          petabox       on            for           \n",
      "with          bag           href          saruman       follow        \n",
      "them          an            tracking      it            crying        \n",
      "\n",
      "\n",
      "topic 25      topic 26      topic 27      topic 28      topic 29      \n",
      "--------      --------      --------      --------      --------      \n",
      "only          brought       div           host          mountains     \n",
      "span          in            class         in            comes         \n",
      "hidden        silver        col           was           it            \n",
      "class         was           sm            being         at            \n",
      "true          it            xs            either        presently     \n",
      "aria          riding        row           year          was           \n",
      "elrond        with          push          on            that          \n",
      "sr            rising        show          by            in            \n",
      "iconochive    beneath       pull          were          again         \n",
      "sons          were          became        that          point         \n",
      "\n",
      "\n",
      "topic 30      topic 31      topic 32      topic 33      topic 34      \n",
      "--------      --------      --------      --------      --------      \n",
      "archive       few           tower         left          pippin        \n",
      "org           fields        captain       right         merry         \n",
      "https         always        guard         rose          who           \n",
      "href          weary         doubt         head          day           \n",
      "details       miles         felt          within        those         \n",
      "title         in            dreadful      else          said          \n",
      "software      tale          they          as            citadel       \n",
      "div           were          great         burning       out           \n",
      "library       there         but           dropdown      one           \n",
      "cd            western       if            was           next          \n",
      "\n",
      "\n",
      "topic 35      topic 36      topic 37      topic 38      topic 39      \n",
      "--------      --------      --------      --------      --------      \n",
      "friends       behind        shall         him           stood         \n",
      "it            beside        has           he            they          \n",
      "in            them          say           find          on            \n",
      "caught        again         ever          with          he            \n",
      "rather        bowed         be            close         with          \n",
      "mighty        low           that          about         that          \n",
      "was           before        for           like          there         \n",
      "script        passage       is            climbed       in            \n",
      "moving        their         but           no            now           \n",
      "rain          bearing       it            kill          as            \n",
      "\n",
      "\n",
      "topic 40      topic 41      topic 42      topic 43      topic 44      \n",
      "--------      --------      --------      --------      --------      \n",
      "going         rode          know          he            ride          \n",
      "it            north         none          was           water         \n",
      "re            came          that          himself       on            \n",
      "hold          green         it            that          fallen        \n",
      "help          ere           mail          as            full          \n",
      "foot          from          quite         now           nay           \n",
      "make          forth         was           for           now           \n",
      "on            horse         guessed       if            from          \n",
      "seems         they          sure          with          body          \n",
      "send          at            clad          wondered      leagues       \n",
      "\n",
      "\n",
      "topic 45      topic 46      topic 47      topic 48      topic 49      \n",
      "--------      --------      --------      --------      --------      \n",
      "knew          long          it            face          had           \n",
      "give          its           almost        spoke         been          \n",
      "they          it            was           near          that          \n",
      "that          was           that          drew          he            \n",
      "he            in            there         he            it            \n",
      "were          but           isn           was           in            \n",
      "swords        ago           they          that          for           \n",
      "at            as            drawing       memory        have          \n",
      "outside       grew          dear          at            all           \n",
      "their         reached       dwarf         boromir       on            \n",
      "\n",
      "\n",
      "topic 50      topic 51      topic 52      topic 53      topic 54      \n",
      "--------      --------      --------      --------      --------      \n",
      "heard         farewell      more          dead          forward       \n",
      "he            doom          than          war           swiftly       \n",
      "that          best          little        they          pelennor      \n",
      "sound         ground        while         hill          top           \n",
      "laughed       he            made          paths         h5            \n",
      "returned      die           for           their         bergil        \n",
      "living        shagrat       no            rohirrim      labour        \n",
      "despair       no            was           in            torches       \n",
      "in            kept          they          was           ease          \n",
      "they          ore           silent        bridge        up            \n",
      "\n",
      "\n",
      "topic 55      topic 56      topic 57      topic 58      topic 59      \n",
      "--------      --------      --------      --------      --------      \n",
      "answered      words         black         road          here          \n",
      "need          cold          gate          towards       took          \n",
      "line          half          against       enemy         leave         \n",
      "he            lost          in            ran           stand         \n",
      "mithrandir    was           was           along         there         \n",
      "in            spoken        it            they          remember      \n",
      "poor          sudden        with          on            they          \n",
      "bed           with          great         speak         stones        \n",
      "so            gollum        their         followed      silence       \n",
      "it            isildur       ruin          that          then          \n",
      "\n",
      "\n",
      "topic 60      topic 61      topic 62      topic 63      topic 64      \n",
      "--------      --------      --------      --------      --------      \n",
      "faramir       company       lord          away          these         \n",
      "land          taken         denethor      far           enough        \n",
      "jowyn         call          indeed        captains      done          \n",
      "also          river         strange       as            shadows       \n",
      "in            eastward      in            running       glad          \n",
      "where         further       said          were          walked        \n",
      "that          horn          this          from          have          \n",
      "said          they          no            but           but           \n",
      "so            great         learn         they          they          \n",
      "metadata      blew          but           nazgyl        all           \n",
      "\n",
      "\n",
      "topic 65      topic 66      topic 67      topic 68      topic 69      \n",
      "--------      --------      --------      --------      --------      \n",
      "eyes          cried         jomer         fell          grey          \n",
      "nor           darkness      better        hobbits       across        \n",
      "maybe         pass          times         strength      they          \n",
      "moment        wild          asked         death         valley        \n",
      "for           years         used          as            short         \n",
      "in            he            than          that          halted        \n",
      "all           up            goes          with          at            \n",
      "hearts        men           guards        were          understand    \n",
      "aside         sprang        them          watched       came          \n",
      "neither       no            with          all           out           \n",
      "\n",
      "\n",
      "topic 70      topic 71      topic 72      topic 73      topic 74      \n",
      "--------      --------      --------      --------      --------      \n",
      "fire          thjoden       you           any           looked        \n",
      "sleep         sea           your          ring          she           \n",
      "cast          was           have          called        her           \n",
      "knights       it            said          was           he            \n",
      "with          golden        are           no            suddenly      \n",
      "was           grass         if            answer        as            \n",
      "muttered      alas          that          it            lady          \n",
      "garden        banner        would         but           at            \n",
      "ahead         were          for           there         but           \n",
      "in            dawn          come          on            then          \n",
      "\n",
      "\n",
      "topic 75      topic 76      topic 77      topic 78      topic 79      \n",
      "--------      --------      --------      --------      --------      \n",
      "will          way           city          down          in            \n",
      "we            found         fair          went          battle        \n",
      "be            without       people        they          sun           \n",
      "us            that          all           into          hour          \n",
      "our           they          most          on            rest          \n",
      "it            there         was           passed        evening       \n",
      "let           in            news          then          peace         \n",
      "come          bottom        chief         over          white         \n",
      "if            for           for           as            died          \n",
      "said          their         there         below         but           \n",
      "\n",
      "\n",
      "topic 80      topic 81      topic 82      topic 83      topic 84      \n",
      "--------      --------      --------      --------      --------      \n",
      "fear          his           my            through       saw           \n",
      "window        he            me            too           east          \n",
      "failed        hand          hope          trees         wind          \n",
      "feel          in            heart         in            south         \n",
      "very          was           it            standing      from          \n",
      "tired         with          keep          it            in            \n",
      "thoughts      at            for           late          that          \n",
      "tree          as            but           passed        sight         \n",
      "children      eyes          all           on            path          \n",
      "in            own           have          then          it            \n",
      "\n",
      "\n",
      "topic 85      topic 86      topic 87      topic 88      topic 89      \n",
      "--------      --------      --------      --------      --------      \n",
      "small         seemed        how           aragorn       forgotten     \n",
      "hills         turned        might         wish          tidings       \n",
      "hear          after         wonder        that          were          \n",
      "voices        it            lie           power         in            \n",
      "like          that          bit           was           they          \n",
      "command       days          be            said          that          \n",
      "butterbur     three         it            but           out           \n",
      "their         was           have          for           built         \n",
      "knees         would         they          arm           their         \n",
      "great         bitter        try           he            flying        \n",
      "\n",
      "\n",
      "topic 90      topic 91      topic 92      topic 93      topic 94      \n",
      "--------      --------      --------      --------      --------      \n",
      "gondor        morning       turn          two           voice         \n",
      "night         alone         perhaps       return        houses        \n",
      "rohan         in            northward     bear          cry           \n",
      "in            longer        hiding        were          as            \n",
      "house         lands         lotho         in            healing       \n",
      "rider         journey       shoulders     but           care          \n",
      "kings         gathering     yet           or            from          \n",
      "was           thus          center        flame         out           \n",
      "steward       hardly        blow          as            that          \n",
      "now           thee          items_list    they          all           \n",
      "\n",
      "\n",
      "topic 95      topic 96      topic 97      topic 98      topic 99      \n",
      "--------      --------      --------      --------      --------      \n",
      "soon          door          sam           side          mordor        \n",
      "already       at            frodo         mountain      air           \n",
      "as            imrahil       said          ores          in            \n",
      "trouble       cannot        well          narrow        was           \n",
      "they          prince        mr            from          earth         \n",
      "there         length        it            by            middle        \n",
      "for           amroth        ve            web           terror        \n",
      "travellers    gathered      got           on            save          \n",
      "cut           dol           he            eastern       that          \n",
      "but           in            but           doing         were          \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))\n",
    "\n",
    "# For each topic (a row in the components_), sort the features (ascending)\n",
    "# Invert rows with [:, ::-1] to make sorting descending\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "# Get the feature names from the vectorizer\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "\n",
    "mglearn.tools.print_topics(topics=range(100), feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Topic modeling on certain chapters of LOTR\n",
    "path= '/Users/blaz/Desktop/LOTR/return-chapters'\n",
    "\n",
    "for file in sorted(glob.glob(os.path.join(path,'*.txt'))):\n",
    "    if file == \"/Users/blaz/Desktop/LOTR/return-chapters/13.txt\":\n",
    "        break\n",
    "        \n",
    "#print(file)\n",
    "\n",
    "MountDoomFile = open(\"/Users/blaz/Desktop/LOTR/return-chapters/13.txt\", 'r')\n",
    "\n",
    "vect = CountVectorizer(max_features=10000, max_df=.15)\n",
    "MountDoom = vect.fit_transform(MountDoomFile)\n",
    "# Count Vectorizer removes all of the words that appear in at least 15% of the text\n",
    "### Unfortunately, this method from the book doesn't work, so I'll have to do this\n",
    "\n",
    "### 10 topics (components)\n",
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                                max_iter=25, random_state=0)\n",
    "\n",
    "document_topics = lda.fit_transform(MountDoom)\n",
    "\n",
    "\n",
    "print(\"lda.components_.shape: {}\".format(lda.components_.shape))\n",
    "lda.components_.shape: (10, 10000)\n",
    "\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names=feature_names, \n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 100 topics (components)\n",
    "lda100 = LatentDirichletAllocation(n_components=100, learning_method=\"batch\",\n",
    "                                   max_iter=25, random_state=0)\n",
    "\n",
    "document_topics100 = lda100.fit_transform(MountDoom)\n",
    "\n",
    "topics = np.array([7, 16, 24, 25, 28, 36, 37, 45, 51, 53, 54, 63, 89, 97])\n",
    "\n",
    "sorting = np.argsort(lda100.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "mglearn.tools.print_topics(topics=topics, feature_names=feature_names,\n",
    "                           sorting=sorting, topics_per_chunk=5, n_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ret_file = open('return.txt', 'r')\n",
    "ret = ret_file.read()\n",
    "\n",
    "# remove HTML jargon\n",
    "ret1 = ret[:-5434]\n",
    "ret = ret1[43252:]\n",
    "\n",
    "words = nltk.word_tokenize(ret)\n",
    "\n",
    "\n",
    "\n",
    "#print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Example JSON request\n",
    "#NOTE: Sentiment140 Polarity values: 0: negative, 2: neutral, 4: positive\n",
    "\n",
    "d = {'data':[{'text':'the titanic was ok'}, {'text':'this sucks'}]}\n",
    "d['data'].append({'text':\"Happy day!\"})\n",
    "\n",
    "r = requests.post('http://www.sentiment140.com/api/bulkClassifyJson?appid=blaz_j1@denison.edu', json=d)\n",
    "js = r.json()\n",
    "\n",
    "print(js['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Example of accessing the polarities\n",
    "\n",
    "for i in range(len(d['data'])):\n",
    "    print(\"Text:\", js['data'][i]['text'], \"\\nPolarity:\", js['data'][i]['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Segment list indexing examples\n",
    "\n",
    "#print(hobbit_segments[15]) ## -- chapter\n",
    "#print(hobbit_segments[0][0]) ## -- segments of chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Working with 'glob'\n",
    "\n",
    "path= '/Users/blaz/Desktop/LOTR/silmarillion-chapters'\n",
    "silm_chapters = []\n",
    "\n",
    "for file in sorted(glob.glob(os.path.join(path,'*.txt'))):\n",
    "    print(file)\n",
    "    f = open(file, 'r')\n",
    "    txt = f.read()\n",
    "    silm_chapters.append(txt)\n",
    "    \n",
    "print(len(silm_chapters))\n",
    "print(silm_chapters[len(silm_chapters)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using 'Counter'\n",
    "\n",
    "biglist = []\n",
    "for chapter in return_chapters_common:\n",
    "    for word in chapter:\n",
    "        biglist.append(word)\n",
    "        \n",
    "Counter(biglist).most_common(10)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
